{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas Gausmann\\sciebo - Gausmann, Thomas (t_gaus04@uni-muenster.de)@uni-muenster.sciebo.de\\Masterarbeit\\price_simulator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import abc\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from collections import deque, namedtuple\n",
    "from typing import List, Tuple\n",
    "import attr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Determine the project root directory (adjust the path as necessary)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../../../..'))\n",
    "print(project_root)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from price_simulator.src.algorithm.demand import MarketDemandStrategy, LogitDemand, PrisonersDilemmaDemand\n",
    "from price_simulator.src.algorithm.agents.simple import AgentStrategy\n",
    "from price_simulator.src.algorithm.equilibrium import EquilibriumCalculator\n",
    "from price_simulator.src.utils.storage import Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class AgentStrategy(metaclass=abc.ABCMeta):\n",
    "    \"\"\"Top-level interface for Price setting agents\"\"\"\n",
    "\n",
    "    marginal_cost: float = attr.ib(default=1.0)\n",
    "    quality: float = attr.ib(default=2.0)\n",
    "\n",
    "    @marginal_cost.validator\n",
    "    def check_marginal_costs(self, attribute, value):\n",
    "        if not value >= 0.0:\n",
    "            raise ValueError(\"Marginal costs must be positive\")\n",
    "\n",
    "    @quality.validator\n",
    "    def check_quality_costs(self, attribute, value):\n",
    "        if not self.marginal_cost <= value:\n",
    "            raise ValueError(\"Quality must be at least as high as marginal costs to be active in market\")\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def play_price(self, state, action_space, n_period, t):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List,\n",
    "        previous_state: Tuple,\n",
    "        state: Tuple,\n",
    "        next_state: Tuple,\n",
    "    ):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def who_am_i(self) -> str:\n",
    "        return type(self).__name__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Always Defect Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class AlwaysDefectAgent(AgentStrategy):\n",
    "    \"\"\"Agent that always defects\"\"\"\n",
    "\n",
    "    def play_price(self, state: Tuple, action_space: List, n_period: int, t: int):\n",
    "        \"\"\"Always play the lowest possible price.\"\"\"\n",
    "        return min(action_space)\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List,\n",
    "        previous_state: Tuple,\n",
    "        state: Tuple,\n",
    "        next_state: Tuple,\n",
    "    ):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Always Max Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class AlwaysMaxAgent(AlwaysDefectAgent):\n",
    "    \"\"\"Agent that always plays maximum price\"\"\"\n",
    "\n",
    "    def play_price(self, state: Tuple, action_space: List, n_period: int, t: int):\n",
    "        \"\"\"Always play the highest possible price.\"\"\"\n",
    "        return max(action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TitForTat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class TitForTat(AlwaysDefectAgent):\n",
    "    \"\"\"\n",
    "    Tit for Tat Agent.\n",
    "\n",
    "    If opponent undercut last period play lowest price.\n",
    "    Otherwise play opponent last periods price.\n",
    "    Agent must be second in list. Only two agents possible.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def play_price(self, state: Tuple, action_space: List, n_period: int, t: int):\n",
    "        if state[0] < state[1]:\n",
    "            return min(action_space)\n",
    "        else:\n",
    "            return state[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follower Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Follower(AlwaysDefectAgent):\n",
    "    \"\"\"\n",
    "    Always plays the minimum price of last period.\n",
    "    Agent must be last in list.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def play_price(self, state: Tuple, action_space: List, n_period: int, t: int):\n",
    "        competitor_actions = state[:-1]\n",
    "        min_competitor = int(np.where(np.array(action_space) == min(competitor_actions))[0])\n",
    "        \n",
    "        return action_space[min_competitor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policies (Exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class ExplorationStrategy(metaclass=abc.ABCMeta):\n",
    "    \"\"\"Top-level interface for Exploration decision.\"\"\"\n",
    "\n",
    "    def who_am_i(self) -> str:\n",
    "        return type(self).__name__\n",
    "\n",
    "    def epsilon(self, length: int, time: int) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def explore(self, n_period: int, t: int) -> bool:\n",
    "        epsilon = self.epsilon(n_period, t)\n",
    "        return random.choices([True, False], weights=[epsilon, 1 - epsilon])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constant Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class EpsilonGreedy(ExplorationStrategy):\n",
    "    \"\"\"Exploration decision based on fixed epsilon greedy policy.\"\"\"\n",
    "\n",
    "    eps: float = attr.ib(default=0.1)\n",
    "\n",
    "    @eps.validator\n",
    "    def check_epsilon(self, attribute, value):\n",
    "        if not 0 <= value <= 1:\n",
    "            raise ValueError(\"Epsilon must lie in [0,1]\")\n",
    "\n",
    "    def who_am_i(self) -> str:\n",
    "        return type(self).__name__ + \" ({})\".format(self.eps)\n",
    "\n",
    "    def epsilon(self, length: int, time: int) -> float:\n",
    "        return self.eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decreasing Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class DecreasingEpsilonGreedy(ExplorationStrategy):\n",
    "    \"\"\"\n",
    "    Exploration decision with decreasing epsilon.\n",
    "    Adapts dynamically to different simulation lengths\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    beta: float = attr.ib(default=0.015)\n",
    "\n",
    "    def epsilon(self, length: int, time: int) -> float:\n",
    "        \"\"\"Returns epsilon for time step, such that after half of the time epsilon is 0.001\"\"\"\n",
    "        return (self.beta ** (1.0 / (length / 2))) ** time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic Environment\n",
    "### Demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class MarketDemandStrategy(metaclass=abc.ABCMeta):\n",
    "    \"\"\"Top-level interface for all market demand modulation.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_quantities(self, prices: Tuple, qualities: Tuple) -> Tuple:\n",
    "        \"\"\"Return demand quanities for each price\"\"\"\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class LogitDemand(MarketDemandStrategy):\n",
    "    \"\"\"Market demand modulation for logit demand\"\"\"\n",
    "\n",
    "    price_sensitivity: float = attr.ib(0.25)  # lower more sensitive\n",
    "    outside_quality: float = attr.ib(0.0)\n",
    "\n",
    "    @price_sensitivity.validator\n",
    "    def check_price_sensitivity(self, attribute, value):\n",
    "        if not 0.005 <= value:\n",
    "            raise ValueError(\"Price Sensitivity must lie above 0.005\")\n",
    "\n",
    "    def get_quantities(self, prices: Tuple, qualities: Tuple) -> Tuple:\n",
    "        denominator = sum((math.exp((a - p) / self.price_sensitivity) for a, p in zip(qualities, prices))) + math.exp(\n",
    "            self.outside_quality / self.price_sensitivity\n",
    "        )\n",
    "        return tuple(math.exp((a - p) / self.price_sensitivity) / denominator for a, p in zip(qualities, prices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class EquilibriumCalculator(object):\n",
    "    \"\"\"Find equilibrium (Monopoly and Nash) for market environment specified by marginal costs, qualities and demand.\"\"\"\n",
    "\n",
    "    demand: MarketDemandStrategy = attr.ib()\n",
    "\n",
    "    def get_nash_equilibrium(self, qualities: List, marginal_costs: List) -> np.array:\n",
    "        \"\"\"Calculate prices that makes market outcome an equilibrium\"\"\"\n",
    "        param = (qualities, marginal_costs)\n",
    "        p0 = np.array(marginal_costs)\n",
    "        return fsolve(self.vector_reaction, p0, args=param)\n",
    "\n",
    "    def profit(\n",
    "        self, own_price: float, prices: np.array, qualities: np.array, marginal_costs: np.array, i: int\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate profit for ith firm if it sets his price to own_price given competitor prices.\"\"\"\n",
    "        temp_prices = copy.deepcopy(prices)\n",
    "        temp_prices[i] = own_price\n",
    "        return -1 * (temp_prices[i] - marginal_costs[i]) * self.demand.get_quantities(temp_prices, qualities)[i]\n",
    "\n",
    "    def reaction_function(self, prices: np.array, qualities: np.array, marginal_costs: np.array, i: float) -> float:\n",
    "        \"\"\"Get price (optimal reaction) that maximizes own profit for given competitor prices.\"\"\"\n",
    "        return minimize(\n",
    "            fun=self.profit,\n",
    "            x0=np.array(marginal_costs[i]),\n",
    "            args=(prices, qualities, marginal_costs, i),\n",
    "            method=\"nelder-mead\",\n",
    "            options={\"xatol\": 1e-8},\n",
    "        ).x[0]\n",
    "\n",
    "    def vector_reaction(self, nash_prices: np.array, qualities: np.array, marginal_costs: np.array) -> np.array:\n",
    "        \"\"\"Vector representation of the fix-point for Nash prices.\"\"\"\n",
    "        return np.array(nash_prices) - np.array(\n",
    "            [self.reaction_function(nash_prices, qualities, marginal_costs, i) for i in range(len(nash_prices))]\n",
    "        )\n",
    "\n",
    "    def get_monopoly_outcome(self, qualities: List, marginal_costs: List) -> np.array:\n",
    "        \"\"\"Get prices that maximize joint profit.\"\"\"\n",
    "        return minimize(\n",
    "            fun=self.joint_profit,\n",
    "            x0=np.array(qualities),\n",
    "            args=(qualities, marginal_costs),\n",
    "            method=\"nelder-mead\",\n",
    "            options={\"xatol\": 1e-8},\n",
    "        ).x\n",
    "\n",
    "    def joint_profit(self, prices: np.array, qualities: np.array, marginal_costs: np.array) -> float:\n",
    "        \"\"\"Return (negative) joint profit for prices.\"\"\"\n",
    "        return -1 * np.sum(\n",
    "            np.multiply(np.subtract(prices, marginal_costs), self.demand.get_quantities(prices, qualities))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Storage:\n",
    "    counter = attr.ib(default=0)\n",
    "    update_steps = attr.ib(init=False)\n",
    "    running_rewards = attr.ib(init=False)\n",
    "    running_quantities = attr.ib(init=False)\n",
    "    running_actions = attr.ib(init=False)\n",
    "    average_rewards = attr.ib(default=None)\n",
    "    average_quantities = attr.ib(default=None)\n",
    "    average_actions = attr.ib(default=None)\n",
    "\n",
    "    def set_up(self, n_agents: int, n_periods: int, desired_length: int = 1000):\n",
    "        self.reset_running_storage(n_agents)\n",
    "        self.update_steps = max(1, np.round(n_periods / desired_length, 0))\n",
    "\n",
    "    def reset_running_storage(self, n_agents: int):\n",
    "        self.running_rewards = np.array([0] * n_agents)\n",
    "        self.running_quantities = np.array([0] * n_agents)\n",
    "        self.running_actions = np.array([0] * n_agents)\n",
    "\n",
    "    def observe(self, rewards: np.array, actions: np.array, quantities: np.array):\n",
    "        self.counter += 1\n",
    "        self.running_rewards = self.incremental_update(rewards, self.running_rewards, self.counter)\n",
    "        self.running_quantities = self.incremental_update(quantities, self.running_quantities, self.counter)\n",
    "        self.running_actions = self.incremental_update(actions, self.running_actions, self.counter)\n",
    "\n",
    "        if self.counter == self.update_steps:\n",
    "            if self.average_actions is not None:\n",
    "                self.average_rewards = np.vstack([self.average_rewards, self.running_rewards])\n",
    "                self.average_actions = np.vstack([self.average_actions, self.running_actions])\n",
    "                self.average_quantities = np.vstack([self.average_quantities, self.running_quantities])\n",
    "            else:\n",
    "                self.average_rewards = copy.deepcopy(self.running_rewards)\n",
    "                self.average_actions = copy.deepcopy(self.running_actions)\n",
    "                self.average_quantities = copy.deepcopy(self.running_quantities)\n",
    "\n",
    "            self.reset_running_storage(len(rewards))\n",
    "            self.counter = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def incremental_update(observation: np.array, average: np.array, cnt: int) -> np.array:\n",
    "        return average + (observation - average) / cnt\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Rewards:\", self.average_rewards)\n",
    "        print(\"Prices:\", self.average_actions)\n",
    "        print(\"Quantities:\", self.average_quantities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "@attr.s\n",
    "class EnvironmentStrategy(metaclass=abc.ABCMeta):\n",
    "    \"\"\"Top-level interface for Environment.\"\"\"\n",
    "\n",
    "    agents: List[AgentStrategy] = attr.ib(factory=list)\n",
    "    possible_prices: List[float] = attr.ib(factory=list)\n",
    "    demand: MarketDemandStrategy = attr.ib(factory=LogitDemand)\n",
    "    nash_prices: np.array = attr.ib(init=False)\n",
    "    monopoly_prices: np.array = attr.ib(init=False)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        \"\"\"Compute Nash Price and Monopoly price after initialization.\"\"\"\n",
    "        if len(self.agents) > 0.0:\n",
    "            if isinstance(self.demand, PrisonersDilemmaDemand):\n",
    "                assert len(self.possible_prices) > 0.0, \"Priosoners Dilemma needs two possible prices\"\n",
    "                self.monopoly_prices = [max(self.possible_prices), max(self.possible_prices)]\n",
    "                self.nash_prices = np.array([min(self.possible_prices), min(self.possible_prices)])\n",
    "            else:\n",
    "                marginal_costs = [agent.marginal_cost for agent in self.agents]\n",
    "                qualities = [agent.quality for agent in self.agents]\n",
    "                self.monopoly_prices = EquilibriumCalculator(demand=self.demand).get_monopoly_outcome(\n",
    "                    qualities, marginal_costs\n",
    "                )\n",
    "                self.nash_prices = EquilibriumCalculator(demand=self.demand).get_nash_equilibrium(\n",
    "                    qualities, marginal_costs\n",
    "                )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def play_game(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class DiscreteSynchronEnvironment(EnvironmentStrategy):\n",
    "    \"\"\"Environment for discrete states and prices.\n",
    "\n",
    "     Before the first iteration, prices are randomly initialized.\n",
    "     Agents set prices at the same time.\n",
    "     After choosing prices, demand and rewards are calculated.\n",
    "     Then agents have the opportunity to learn.\n",
    "     \"\"\"\n",
    "\n",
    "    n_periods: int = attr.ib(default=1)\n",
    "    markup: float = attr.ib(default=0.1)\n",
    "    n_prices: int = attr.ib(default=15)\n",
    "    convergence_after: int = attr.ib(default=np.inf)\n",
    "    history_after: int = attr.ib(default=np.inf)\n",
    "    price_history: List = attr.ib(factory=list)\n",
    "    quantity_history: List = attr.ib(factory=list)\n",
    "    reward_history: List = attr.ib(factory=list)\n",
    "    storage: Storage = attr.ib(factory=Storage)\n",
    "    debug: bool = attr.ib(default=False)\n",
    "\n",
    "    @n_periods.validator\n",
    "    def check_n_periods(self, attribute, value):\n",
    "        if not 0 < value:\n",
    "            raise ValueError(\"Number of periods must be strictly positive\")\n",
    "\n",
    "    @markup.validator\n",
    "    def check_markup(self, attribute, value):\n",
    "        if not 0 <= value:\n",
    "            raise ValueError(\"Price markup must be positive\")\n",
    "\n",
    "    @n_prices.validator\n",
    "    def check_n_prices(self, attribute, value):\n",
    "        if not 0 < value:\n",
    "            raise ValueError(\"Number of prices must be strictly positive\")\n",
    "\n",
    "    def play_game(self) -> int:\n",
    "\n",
    "        qualities = tuple(agent.quality for agent in self.agents)\n",
    "        marginal_costs = tuple(agent.marginal_cost for agent in self.agents)\n",
    "\n",
    "        # initialize first rounds\n",
    "        if len(self.possible_prices) == 0:\n",
    "            self.possible_prices = self.get_price_range(\n",
    "                min(self.nash_prices), max(self.monopoly_prices), self.markup, self.n_prices\n",
    "            )\n",
    "\n",
    "        previous_state = tuple(random.choices(self.possible_prices, k=len(self.agents)))\n",
    "        state = tuple(\n",
    "            agent.play_price(previous_state, self.possible_prices, self.n_periods, 0) for agent in self.agents\n",
    "        )\n",
    "        quantities = self.demand.get_quantities(state, qualities)\n",
    "        previous_rewards = np.multiply(np.subtract(state, marginal_costs), quantities)\n",
    "\n",
    "        # set up storage\n",
    "        self.storage.set_up(len(self.agents), self.n_periods)\n",
    "\n",
    "        #Begin simulation\n",
    "        for t in range(self.n_periods):\n",
    "            # Progress indicator\n",
    "            if t % max(1, self.n_periods // 100) == 0:\n",
    "                print(f\"Period {t}/{self.n_periods} ({(t / self.n_periods) * 100:.2f}%)\")\n",
    "                \n",
    "            # agents decide about there prices (hereafter is the state different)\n",
    "            next_state = tuple(\n",
    "                agent.play_price(state, self.possible_prices, self.n_periods, t) for agent in self.agents\n",
    "            )\n",
    "\n",
    "            # demand is estimated for prices\n",
    "            quantities = self.demand.get_quantities(next_state, qualities)\n",
    "            rewards = np.multiply(np.subtract(next_state, marginal_costs), quantities)\n",
    "\n",
    "            # assert that everything is correct\n",
    "            assert (np.array(quantities) >= 0.0).all(), \"Quantities cannot be negative\"\n",
    "            assert (np.array(next_state) >= 0.0).all(), \"Prices cannot be negative\"\n",
    "\n",
    "            # agents learn\n",
    "            for agent, action, previous_action, reward, previous_reward in zip(\n",
    "                self.agents, next_state, state, rewards, previous_rewards\n",
    "            ):\n",
    "                agent.learn(\n",
    "                    previous_reward=previous_reward,\n",
    "                    reward=reward,\n",
    "                    previous_action=previous_action,\n",
    "                    action=action,\n",
    "                    action_space=self.possible_prices,\n",
    "                    previous_state=previous_state,\n",
    "                    state=state,\n",
    "                    next_state=next_state,\n",
    "                )\n",
    "\n",
    "            # update variables\n",
    "            previous_state = copy.deepcopy(state)\n",
    "            state = copy.deepcopy(next_state)\n",
    "            previous_rewards = copy.deepcopy(rewards)\n",
    "\n",
    "            # save prices for the last periods\n",
    "            if t > self.history_after:\n",
    "                self.price_history.append(previous_state)\n",
    "                self.quantity_history.append(quantities)\n",
    "                self.reward_history.append(rewards)\n",
    "\n",
    "            # Fill storage\n",
    "            self.storage.observe(rewards, state, quantities)\n",
    "\n",
    "        return t\n",
    "    \n",
    "    def show_price_matrix_heatmap(self):\n",
    "        \"\"\"Display a heatmap with the best response prices for each price pair.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        self.possible_prices = self.get_price_range(\n",
    "            min(self.nash_prices), max(self.monopoly_prices), self.markup, self.n_prices\n",
    "        )\n",
    "        price_matrix = np.zeros((len(self.possible_prices), len(self.possible_prices)))\n",
    "\n",
    "        for i, price_1 in enumerate(self.possible_prices):\n",
    "            for j, price_2 in enumerate(self.possible_prices):\n",
    "                state = (price_1, price_2)\n",
    "                qualities = tuple(agent.quality for agent in self.agents)\n",
    "                marginal_costs = tuple(agent.marginal_cost for agent in self.agents)\n",
    "                quantities = self.demand.get_quantities(state, qualities)\n",
    "                rewards = np.multiply(np.subtract(state, marginal_costs), quantities)\n",
    "                price_matrix[i, j] = rewards[0]  # Assuming we are interested in the reward of the first agent\n",
    "\n",
    "        rounded_prices = [round(price, 4) for price in self.possible_prices]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(price_matrix, xticklabels=rounded_prices, yticklabels=rounded_prices, cmap=\"viridis\")\n",
    "        plt.title(\"Price Matrix Heatmap (Best Response Prices)\")\n",
    "        plt.xlabel(\"Price of Agent 2\")\n",
    "        plt.ylabel(\"Price of Agent 1\")\n",
    "        plt.gca().invert_yaxis()  # Ensure the y-axis starts with the lowest price\n",
    "\n",
    "        # Mark Nash price\n",
    "        nash_price_1, nash_price_2 = self.nash_prices\n",
    "        nash_idx_1 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(nash_price_1, 2)))\n",
    "        nash_idx_2 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(nash_price_2, 2)))\n",
    "        plt.scatter(nash_idx_2 + 0.5, nash_idx_1 + 0.5, color='red', label='Nash Price', s=100)\n",
    "\n",
    "        # Mark Monopoly/Cooperation price\n",
    "        coop_price_1, coop_price_2 = self.monopoly_prices\n",
    "        coop_idx_1 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(coop_price_1, 2)))\n",
    "        coop_idx_2 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(coop_price_2, 2)))\n",
    "        plt.scatter(coop_idx_2 + 0.5, coop_idx_1 + 0.5, color='blue', label='Cooperation/Monopoly Price', s=100)\n",
    "\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_joint_profit(self):\n",
    "        \"\"\"Plot the joint profit function over a range of prices.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        self.possible_prices = self.get_price_range(\n",
    "            min(self.nash_prices), max(self.monopoly_prices), self.markup, self.n_prices\n",
    "        )\n",
    "        price_matrix = np.zeros((len(self.possible_prices), len(self.possible_prices)))\n",
    "        qualities = tuple(agent.quality for agent in self.agents)\n",
    "        marginal_costs = tuple(agent.marginal_cost for agent in self.agents)\n",
    "        for i, price_1 in enumerate(self.possible_prices):\n",
    "            for j, price_2 in enumerate(self.possible_prices):\n",
    "                state = (price_1, price_2)\n",
    "                joint_profit = EquilibriumCalculator(demand=self.demand).joint_profit(\n",
    "                    state, qualities, marginal_costs\n",
    "                )\n",
    "                price_matrix[i, j] = joint_profit\n",
    "        rounded_prices = [round(price, 2) for price in self.possible_prices]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(price_matrix, xticklabels=rounded_prices, yticklabels=rounded_prices, cmap=\"coolwarm\")\n",
    "        plt.title(\"Joint Profit Function\")\n",
    "        plt.xlabel(\"Price of Agent 2\")\n",
    "        plt.ylabel(\"Price of Agent 1\")\n",
    "        plt.gca().invert_yaxis()  # Ensure the y-axis starts with the lowest price\n",
    "\n",
    "        # Mark Nash price\n",
    "        nash_price_1, nash_price_2 = self.nash_prices\n",
    "        nash_idx_1 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(nash_price_1, 2)))\n",
    "        nash_idx_2 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(nash_price_2, 2)))\n",
    "        plt.scatter(nash_idx_2 + 0.5, nash_idx_1 + 0.5, color='red', label='Nash Price', s=100)\n",
    "\n",
    "        # Mark Monopoly/Cooperation price\n",
    "        coop_price_1, coop_price_2 = self.monopoly_prices\n",
    "        coop_idx_1 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(coop_price_1, 2)))\n",
    "        coop_idx_2 = min(range(len(rounded_prices)), key=lambda i: abs(rounded_prices[i] - round(coop_price_2, 2)))\n",
    "        plt.scatter(coop_idx_2 + 0.5, coop_idx_1 + 0.5, color='blue', label='Cooperation/Monopoly Price', s=100)\n",
    "\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_price_range(nash_price: float, monopoly_price: float, markup: float, n_step: int) -> List:\n",
    "        increase = (monopoly_price - nash_price) * markup\n",
    "        return list(np.linspace(nash_price - increase, monopoly_price + increase, n_step))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create an environment with two AlwaysDefectAgents\n",
    "env = DiscreteSynchronEnvironment(\n",
    "\tmarkup=0.1,\n",
    "\tn_periods=1000,\n",
    "\tpossible_prices=[],\n",
    "\tn_prices=15,\n",
    "\tdemand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "\thistory_after=100,\n",
    "\tagents=[\n",
    "\t\tAlwaysDefectAgent(marginal_cost=1.0, quality=2.0),\n",
    "\t\tAlwaysDefectAgent(marginal_cost=1.0, quality=2.0),\n",
    "\t],\n",
    ")\n",
    "\n",
    "# Print the price matrix\n",
    "env.show_price_matrix_heatmap()\n",
    "env.plot_joint_profit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test with 2 Always defect agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the AlwaysDefectAgent\n",
    "\n",
    "def create_subplot(data, label):\n",
    "    for series in data:\n",
    "        plt.plot(series, label=label)\n",
    "    plt.legend()\n",
    "\n",
    "def test_always_defect_agent():\n",
    "    # Create an environment with AlwaysDefectAgent\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=1000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=100,\n",
    "        agents=[\n",
    "            AlwaysDefectAgent(marginal_cost=1.0, quality=2.0),\n",
    "            AlwaysDefectAgent(marginal_cost=1.0, quality=2.0),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Simulate the environment\n",
    "    env.play_game()\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_1 = [price[0] for price in env.price_history]\n",
    "    price_history_2 = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    create_subplot([price_history_1, price_history_2], label=\"Price\")\n",
    "    plt.title(\"Price History\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_1 = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_2 = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    create_subplot([reward_history_1, reward_history_2], label=\"Reward\")\n",
    "    plt.title(\"Reward History\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.show()\n",
    "\n",
    "test_always_defect_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LSTM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from price_simulator.src.algorithm.agents.buffer import SequentialReplayBuffer\n",
    "from price_simulator.src.algorithm.agents.simple import AgentStrategy\n",
    "from price_simulator.src.algorithm.policies import EpsilonGreedy, ExplorationStrategy\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "@attr.s\n",
    "class SimpleLSTMAgent(AgentStrategy):\n",
    "    \"\"\"Simplified LSTM Agent using sequences of past states\"\"\"\n",
    "\n",
    "    # LSTM Network\n",
    "    lstm: LSTMModel = attr.ib(default=None)\n",
    "    hidden_nodes: int = attr.ib(default=32)\n",
    "    sequence_length: int = attr.ib(default=5)  # Number of past states to use\n",
    "    state_history: List[Tuple[float, ...]] = attr.ib(factory=list)\n",
    "\n",
    "    # General\n",
    "    decision: ExplorationStrategy = attr.ib(factory=EpsilonGreedy)\n",
    "    discount: float = attr.ib(default=0.95)\n",
    "    learning_rate: float = attr.ib(default=0.1)\n",
    "\n",
    "    loss_history: List[float] = attr.ib(factory=list, init=False)\n",
    "\n",
    "    @discount.validator\n",
    "    def check_discount(self, attribute, value):\n",
    "        if not 0 <= value <= 1:\n",
    "            raise ValueError(\"Discount factor must lie in [0,1]\")\n",
    "\n",
    "    @learning_rate.validator\n",
    "    def check_learning_rate(self, attribute, value):\n",
    "        if not 0 <= value < 1:\n",
    "            raise ValueError(\"Learning rate must lie in [0,1)\")\n",
    "\n",
    "    def who_am_i(self) -> str:\n",
    "        return type(self).__name__ + \" (gamma: {}, alpha: {}, policy: {}, quality: {}, mc: {})\".format(\n",
    "            self.discount, self.learning_rate, self.decision.who_am_i(), self.quality, self.marginal_cost\n",
    "        )\n",
    "\n",
    "    def update_state_history(self, state: Tuple[float]):\n",
    "        #ToDo: make more versatile to use in other agents\n",
    "        if not isinstance(self.state_history, list):\n",
    "            self.state_history = []\n",
    "        \"\"\"Update the history of states with the new state.\"\"\"\n",
    "        self.state_history.append(state)\n",
    "        if len(self.state_history) > self.sequence_length:\n",
    "            self.state_history.pop(0)\n",
    "\n",
    "    def play_price(self, state: Tuple[float], action_space: List[float], n_period: int, t: int) -> float:\n",
    "        \"\"\"Returns an action by either following greedy policy or experimentation.\"\"\"\n",
    "\n",
    "        # Update state history\n",
    "        self.update_state_history(state)\n",
    "\n",
    "        # Initialize LSTM network if necessary\n",
    "        if not self.lstm:\n",
    "            self.lstm = self.initialize_network(len(state), len(action_space))\n",
    "\n",
    "        # Play action\n",
    "        if self.decision.explore(n_period, t):\n",
    "            return random.choice(action_space)\n",
    "        else:\n",
    "            # Use state history as input to the LSTM network\n",
    "            states_input = torch.tensor(self.scale_sequence(self.state_history, action_space)).float().unsqueeze(0)\n",
    "            action_values = self.lstm(states_input).detach().numpy()\n",
    "            if sum(np.isclose(action_values[0], action_values[0].max())) > 1:\n",
    "                optimal_action_index = np.random.choice(\n",
    "                    np.flatnonzero(np.isclose(action_values[0], action_values[0].max()))\n",
    "                )\n",
    "            else:\n",
    "                optimal_action_index = np.argmax(action_values[0])\n",
    "            return action_space[optimal_action_index]\n",
    "        \n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List[float],\n",
    "        previous_state: Tuple[float],\n",
    "        state: Tuple[float],\n",
    "        next_state: Tuple[float],\n",
    "    ):\n",
    "        \"\"\"Update the LSTM network based on the observed rewards and actions.\"\"\"\n",
    "        # Update state history with the current state\n",
    "        self.update_state_history(state)\n",
    "\n",
    "        # Create a sequence of state history length for the next state\n",
    "        next_state_history = self.state_history[-self.sequence_length:] + [next_state]\n",
    "        # Scale the input sequences\n",
    "        states_input = torch.tensor(self.scale_sequence(self.state_history, action_space)).float().unsqueeze(0)\n",
    "        next_states_input = torch.tensor(self.scale_sequence(next_state_history, action_space)).float().unsqueeze(0)\n",
    "\n",
    "        # Compute the target Q-values using the Bellman equation\n",
    "        next_optimal_q = self.lstm(next_states_input).max().item()\n",
    "        target = reward + self.discount * next_optimal_q\n",
    "\n",
    "        # Get the local estimates from the LSTM network\n",
    "        local_estimates = self.lstm(states_input)\n",
    "        action_idx = np.atleast_1d(action_space == action).nonzero()[0]\n",
    "        target_tensor = local_estimates.clone().detach()\n",
    "        target_tensor[0, action_idx] = target\n",
    "\n",
    "        # Update the LSTM network using backpropagation\n",
    "        optimizer = optim.Adam(self.lstm.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.MSELoss()(local_estimates, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Store the loss value\n",
    "        self.loss_history.append(loss.item())\n",
    "        # Debugging: ###print loss and target values\n",
    "        #print(f\"Loss: {loss.item()}, Target: {target}, Local Estimates: {local_estimates[0, action_idx].item()}\")\n",
    "\n",
    "    def initialize_network(self, n_agents: int, n_actions: int):\n",
    "        \"\"\"Create a neural network with one output node per possible action\"\"\"\n",
    "        return LSTMModel(input_size=n_agents, hidden_size=self.hidden_nodes, output_size=n_actions)\n",
    "\n",
    "    def scale_sequence(self, sequences: List[Tuple], action_space: List) -> np.array:\n",
    "        \"\"\"Scale float input sequences to range from 0 to 1.\"\"\"\n",
    "        max_action = max(action_space)\n",
    "        min_action = min(action_space)\n",
    "        return np.array([\n",
    "            np.multiply(np.divide(np.array(seq) - min_action, max_action - min_action), 1) for seq in sequences\n",
    "        ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Simple LSTM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_lstm_vs_always_defect():\n",
    "    # Create an environment with one SimpleLSTMAgent and one AlwaysDefectAgent\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=10000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=100,\n",
    "        agents=[\n",
    "            SimpleLSTMAgent(\n",
    "                discount=0.95, learning_rate=0.001, decision=DecreasingEpsilonGreedy(), marginal_cost=1.0, quality=2.0, state_history = 50\n",
    "            ),\n",
    "            AlwaysMaxAgent(\n",
    "                \n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Simulate the environment\n",
    "    env.play_game()\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_lstm = [price[0] for price in env.price_history]\n",
    "    price_history_defect = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_history_lstm, label=\"Simple LSTM Agent\")\n",
    "    plt.plot(price_history_defect, label=\"Test Agent\")\n",
    "    plt.title(\"Price History: Simple LSTM Agent vs Test Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_lstm = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_defect = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(reward_history_lstm, label=\"Simple LSTM Agent\")\n",
    "    plt.plot(reward_history_defect, label=\"Test Agent\")\n",
    "    plt.title(\"Reward History: Simple LSTM Agent vs Test Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_simple_lstm_vs_always_defect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replaybuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size=None):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        if buffer_size is None:\n",
    "            self.buffer_size = 10000\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\"])\n",
    "\n",
    "    def add(self, state, action, reward, next_state):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=batch_size)\n",
    "\n",
    "        states = np.vstack([e.state for e in experiences if e is not None])\n",
    "        actions = np.vstack([e.action for e in experiences if e is not None])\n",
    "        rewards = np.vstack([e.reward for e in experiences if e is not None])\n",
    "        next_states = np.vstack([e.next_state for e in experiences if e is not None])\n",
    "\n",
    "        return states, actions, rewards, next_states\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with only Target Network\n",
    "Idea: Replaybuffer breaks correlation in sequences. But LSTM is trained to utilize these correlations, no? So, remove replaybuffer and only use Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class LSTMTargetAgent(SimpleLSTMAgent):\n",
    "\t\"\"\"LSTM Agent with Target Network but without Replay Buffer\"\"\"\n",
    "\n",
    "\t# Target Network\n",
    "\ttarget_network: LSTMModel = attr.ib(default=None)\n",
    "\tupdate_target_after: int = attr.ib(default=100)\n",
    "\tupdate_counter: int = attr.ib(default=0)\n",
    "\n",
    "\tdef initialize_network(self, n_agents: int, n_actions: int):\n",
    "\t\t\"\"\"Initialize both local and target networks.\"\"\"\n",
    "\t\tlocal_network = super().initialize_network(n_agents, n_actions)\n",
    "\t\ttarget_network = super().initialize_network(n_agents, n_actions)\n",
    "\t\ttarget_network.load_state_dict(local_network.state_dict())  # Synchronize weights\n",
    "\t\tself.target_network = target_network\n",
    "\t\treturn local_network\n",
    "\n",
    "\tdef learn(\n",
    "\t\tself,\n",
    "\t\tprevious_reward: float,\n",
    "\t\treward: float,\n",
    "\t\tprevious_action: float,\n",
    "\t\taction: float,\n",
    "\t\taction_space: List[float],\n",
    "\t\tprevious_state: Tuple[float],\n",
    "\t\tstate: Tuple[float],\n",
    "\t\tnext_state: Tuple[float],\n",
    "\t):\n",
    "\t\t\"\"\"Train the LSTM network using the target network.\"\"\"\n",
    "\t\t# Update state history\n",
    "\t\tself.update_state_history(state)\n",
    "\n",
    "\t\t# Create a sequence of state history length for the next state\n",
    "\t\tnext_state_history = self.state_history[-self.sequence_length:] + [next_state]\n",
    "\t\t# Scale the input sequences\n",
    "\t\tstates_input = torch.tensor(self.scale_sequence(self.state_history, action_space)).float().unsqueeze(0)\n",
    "\t\tnext_states_input = torch.tensor(self.scale_sequence(next_state_history, action_space)).float().unsqueeze(0)\n",
    "\n",
    "\t\t# Compute the target Q-values using the target network\n",
    "\t\t# ToDo maybe try advantage learning\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnext_optimal_q = self.target_network(next_states_input).max().item()\n",
    "\t\t\ttarget = reward + self.discount * next_optimal_q\n",
    "\n",
    "\t\t# Get the local estimates from the LSTM network\n",
    "\t\tlocal_estimates = self.lstm(states_input)\n",
    "\t\taction_idx = np.atleast_1d(action_space == action).nonzero()[0]\n",
    "\t\ttarget_tensor = local_estimates.clone().detach()\n",
    "\t\ttarget_tensor[0, action_idx] = target\n",
    "\n",
    "\t\t# Update the LSTM network using backpropagation\n",
    "\t\toptimizer = optim.Adam(self.lstm.parameters(), lr=self.learning_rate)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = nn.MSELoss()(local_estimates, target_tensor)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# Update the target network periodically\n",
    "\t\tself.update_counter += 1\n",
    "\t\tif self.update_counter >= self.update_target_after:\n",
    "\t\t\tself.target_network.load_state_dict(self.lstm.state_dict())\n",
    "\t\t\tself.update_counter = 0\n",
    "\t\t\tprint(\"Target network updated.\")\n",
    "\n",
    "\t\t# Store the loss value\n",
    "\t\tself.loss_history.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm_target_vs_always_defect():\n",
    "\t# Create an environment with one LSTMTargetAgent and one AlwaysDefectAgent\n",
    "\tenv = DiscreteSynchronEnvironment(\n",
    "\t\tmarkup=0.1,\n",
    "\t\tn_periods=10000,\n",
    "\t\tpossible_prices=[],\n",
    "\t\tn_prices=15,\n",
    "\t\tdemand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "\t\thistory_after=100,\n",
    "\t\tagents=[\n",
    "\t\t\tLSTMTargetAgent(\n",
    "\t\t\t\tdiscount=0.95,\n",
    "\t\t\t\tlearning_rate=0.001,\n",
    "\t\t\t\tdecision=DecreasingEpsilonGreedy(),\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t\tsequence_length=10,\n",
    "\t\t\t\tupdate_target_after=100,\n",
    "\t\t\t),\n",
    "\t\t\tAlwaysDefectAgent(\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t),\n",
    "\t\t],\n",
    "\t)\n",
    "\n",
    "\t# Simulate the environment\n",
    "\tenv.play_game()\n",
    "\n",
    "\t# Analyze and visualize results\n",
    "\tprice_history_lstm = [price[0] for price in env.price_history]\n",
    "\tprice_history_defect = [price[1] for price in env.price_history]\n",
    "\n",
    "\t# Plot price history\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(price_history_lstm, label=\"LSTM Target Agent\")\n",
    "\tplt.plot(price_history_defect, label=\"Always Defect Agent\")\n",
    "\tplt.title(\"Price History: LSTM Target Agent vs Test Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Price\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Plot reward history\n",
    "\treward_history_lstm = [reward[0] for reward in env.reward_history]\n",
    "\treward_history_defect = [reward[1] for reward in env.reward_history]\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(reward_history_lstm, label=\"LSTM Target Agent\")\n",
    "\tplt.plot(reward_history_defect, label=\"Test Agent\")\n",
    "\tplt.title(\"Reward History: LSTM Target Agent vs Test Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Reward\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "test_lstm_target_vs_always_defect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SequentialReplayBuffer:\n",
    "    \"\"\"Replay buffer that stores sequences of states, actions, and rewards.\n",
    "    Basic idea here: store the states, actions, and rewards as an array.\n",
    "    When needed, sample based on a random index\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size=None):\n",
    "        \"\"\"Initialize a SequentialReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "        \"\"\"\n",
    "        if buffer_size is None:\n",
    "            buffer_size = 10000\n",
    "        self.buffer_size = buffer_size\n",
    "        self.states = deque(maxlen=buffer_size)  # Stores individual states\n",
    "        self.actions = deque(maxlen=buffer_size)  # Stores actions\n",
    "        self.rewards = deque(maxlen=buffer_size)  # Stores rewards\n",
    "\n",
    "    def add(self, state, action, reward):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def sample(self, batch_size, sequence_length):\n",
    "        \"\"\"Sample a batch of sequential experiences from memory.\n",
    "        Params\n",
    "        ======\n",
    "            batch_size: Number of sequences to sample\n",
    "            sequence_length: Length of each sequence of states\n",
    "        Returns\n",
    "        =======\n",
    "            sampled_states: Batch of sequences of states\n",
    "            sampled_actions: Actions corresponding to the end of sampled_states sequence\n",
    "            sampled_rewards: Rewards corresponding to the end of sampled_states sequence\n",
    "            next_states: Batch of sequences of next states, shifted by one step\n",
    "        \"\"\"\n",
    "        available_length = len(self.states)\n",
    "        if available_length < sequence_length:\n",
    "            print(f\"Buffer has fewer entries ({available_length}) than the requested sequence length ({sequence_length}). Adjusting sequence length.\")\n",
    "            sequence_length = available_length\n",
    "\n",
    "        max_start_index = available_length - sequence_length\n",
    "        if max_start_index + 1 < batch_size:\n",
    "            print(f\"Buffer has fewer sequences ({max_start_index + 1}) than the requested batch size ({batch_size}). Adjusting batch size.\")\n",
    "            batch_size = max_start_index + 1\n",
    "\n",
    "        indices = random.sample(range(max(0, max_start_index + 1)), batch_size)\n",
    "\n",
    "        sampled_states = []\n",
    "        sampled_actions = []\n",
    "        sampled_rewards = []\n",
    "        sampled_next_states = []\n",
    "\n",
    "        for idx in indices:\n",
    "            # Sequence of states\n",
    "            state_sequence = list(self.states)[idx:idx + sequence_length]\n",
    "            next_state_sequence = list(self.states)[idx + 1:idx + sequence_length + 1]\n",
    "\n",
    "            # Pad sequences if they are shorter than the requested length\n",
    "            while len(state_sequence) < sequence_length:\n",
    "                state_sequence.append(np.zeros_like(state_sequence[0]))\n",
    "            while len(next_state_sequence) < sequence_length:\n",
    "                next_state_sequence.append(np.zeros_like(next_state_sequence[0]))\n",
    "\n",
    "            sampled_states.append(state_sequence)\n",
    "            sampled_next_states.append(next_state_sequence)\n",
    "\n",
    "            # Action and reward at the end of the sequence\n",
    "            sampled_actions.append(self.actions[idx + sequence_length - 1])\n",
    "            sampled_rewards.append(self.rewards[idx + sequence_length - 1])\n",
    "\n",
    "        return (\n",
    "            np.array(sampled_states),\n",
    "            np.array(sampled_actions),\n",
    "            np.array(sampled_rewards),\n",
    "            np.array(sampled_next_states),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of the buffer.\"\"\"\n",
    "        return len(self.states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Agent with Replay Buffer and Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@attr.s\n",
    "class LSTMReplayAgent(SimpleLSTMAgent):\n",
    "    \"\"\"LSTM Agent with Replay Buffer and Target Network\"\"\"\n",
    "\n",
    "    # Replay Buffer\n",
    "    replay_buffer: SequentialReplayBuffer = attr.ib(factory=lambda: SequentialReplayBuffer(buffer_size=10000))\n",
    "    batch_size: int = attr.ib(default=32)\n",
    "\n",
    "    # Target and Local Networks\n",
    "    target_network: LSTMModel = attr.ib(default=None)\n",
    "    update_target_after: int = attr.ib(default=100)\n",
    "    update_counter: int = attr.ib(default=0)\n",
    "\n",
    "    def initialize_network(self, n_agents: int, n_actions: int):\n",
    "        \"\"\"Initialize both local and target networks.\"\"\"\n",
    "        local_network = super().initialize_network(n_agents, n_actions)\n",
    "        target_network = super().initialize_network(n_agents, n_actions)\n",
    "        target_network.load_state_dict(local_network.state_dict())  # Synchronize weights\n",
    "        self.target_network = target_network\n",
    "        return local_network\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List[float],\n",
    "        previous_state: Tuple[float],\n",
    "        state: Tuple[float],\n",
    "        next_state: Tuple[float],\n",
    "    ):\n",
    "        \"\"\"Train the LSTM network using replay buffer and target network.\"\"\"\n",
    "        # Scale the current state before adding it to the replay buffer\n",
    "        scaled_state = self.scale_sequence([state], action_space)[0]\n",
    "        self.replay_buffer.add(scaled_state, action, reward)\n",
    "\n",
    "        # Ensure the buffer has enough data to sample sequences\n",
    "        required_size = self.batch_size + self.sequence_length\n",
    "        if len(self.replay_buffer) < required_size:\n",
    "            #print(f\"Warm-up: Not enough experiences in the buffer to train. Current size: {len(self.replay_buffer)}\")\n",
    "            return\n",
    "\n",
    "        # Sample a batch of experiences\n",
    "        states, actions, rewards, next_states = self.replay_buffer.sample(self.batch_size, self.sequence_length)  # Convert to tensors\n",
    "        states_input = torch.tensor(states).float()\n",
    "        next_states_input = torch.tensor(next_states).float()\n",
    "        actions_tensor = torch.tensor([action_space.index(a) for a in actions])\n",
    "        rewards_tensor = torch.tensor(rewards).float()\n",
    "\n",
    "        # Compute target Q-values using the target network\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_network(next_states_input).max(dim=1)[0]\n",
    "            targets = rewards_tensor + self.discount * next_q_values\n",
    "\n",
    "        # Get current Q-values from the local network\n",
    "        local_q_values = self.lstm(states_input)\n",
    "        predicted_q_values = local_q_values.gather(1, actions_tensor.unsqueeze(1)).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(predicted_q_values, targets)\n",
    "\n",
    "        # Perform gradient descent step\n",
    "        optimizer = optim.Adam(self.lstm.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the target network periodically\n",
    "        self.update_counter += 1\n",
    "        if self.update_counter >= self.update_target_after:\n",
    "            self.target_network.load_state_dict(self.lstm.state_dict())\n",
    "            self.update_counter = 0\n",
    "            print(\"Target network updated.\")\n",
    "\n",
    "        # Store the loss value\n",
    "        self.loss_history.append(loss.item())\n",
    "        #print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    def play_price(self, state: Tuple[float], action_space: List[float], n_period: int, t: int) -> float:\n",
    "        \"\"\"Returns an action by either following greedy policy or experimentation.\"\"\"\n",
    "        self.update_state_history(state)\n",
    "\n",
    "        if not self.lstm:\n",
    "            self.lstm = self.initialize_network(len(state), len(action_space))\n",
    "            \n",
    "\n",
    "        if self.decision.explore(n_period, t):\n",
    "            return random.choice(action_space)\n",
    "        else:\n",
    "            states_input = torch.tensor(self.scale_sequence(self.state_history, action_space)).float().unsqueeze(0)\n",
    "            action_values = self.lstm(states_input).detach().numpy()\n",
    "            return action_space[np.argmax(action_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm_replay_vs_always_defect():\n",
    "    # Create an environment with one LSTMReplayAgent and one AlwaysDefectAgent\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=50000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=100,\n",
    "        agents=[\n",
    "            LSTMReplayAgent(\n",
    "                discount=0.95,\n",
    "                learning_rate=0.001,\n",
    "                decision=DecreasingEpsilonGreedy(),\n",
    "                marginal_cost=1.0,\n",
    "                quality=2.0,\n",
    "                sequence_length=10,\n",
    "                batch_size=128,\n",
    "                update_target_after=2500,\n",
    "                replay_buffer=SequentialReplayBuffer(buffer_size=10000),\n",
    "            ),\n",
    "            AlwaysDefectAgent(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Simulate the environment\n",
    "    env.play_game()\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_lstm = [price[0] for price in env.price_history]\n",
    "    price_history_defect = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_history_lstm, label=\"LSTM Replay Agent\")\n",
    "    plt.plot(price_history_defect, label=\"Always Defect Agent\")\n",
    "    plt.title(\"Price History: LSTM Replay Agent vs Test Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_lstm = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_defect = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(reward_history_lstm, label=\"LSTM Replay Agent\")\n",
    "    plt.plot(reward_history_defect, label=\"Always Defect Agent\")\n",
    "    plt.title(\"Reward History: LSTM Replay Agent vs Always Defect Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_lstm_replay_vs_always_defect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyTorch Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage, TensorDictReplayBuffer\n",
    "from tensordict import TensorDict\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@attr.s\n",
    "class LSTMReplayAgent(AgentStrategy):\n",
    "    \"\"\"LSTM Agent with Replay Buffer for Reinforcement Learning\"\"\"\n",
    "\n",
    "    # LSTM Network\n",
    "    lstm: LSTMModel = attr.ib(default=None)\n",
    "    hidden_nodes: int = attr.ib(default=32)\n",
    "    sequence_length: int = attr.ib(default=5)  # Number of past states to use\n",
    "    state_history: List[Tuple[float, ...]] = attr.ib(factory=list)\n",
    "\n",
    "    # Target Network\n",
    "    target_lstm: LSTMModel = attr.ib(default=None, init=False)  # Target network\n",
    "    update_counter: int = attr.ib(default=0, init=False)  # Counter for target updates\n",
    "    update_target_after: int = attr.ib(default=250)\n",
    "\n",
    "    # Replay Buffer\n",
    "    replay_buffer_capacity: int = attr.ib(default=1000)\n",
    "    batch_size: int = attr.ib(default=32)\n",
    "\n",
    "    # General\n",
    "    decision: ExplorationStrategy = attr.ib(factory=DecreasingEpsilonGreedy)\n",
    "    discount: float = attr.ib(default=0.95)\n",
    "    learning_rate: float = attr.ib(default=0.001)\n",
    "    loss_history: List[float] = attr.ib(factory=list, init=False)\n",
    "\n",
    "    # Debugging\n",
    "    debug: bool = attr.ib(default=False)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        # Initialize replay buffer\n",
    "        self.replay_buffer = TensorDictReplayBuffer(\n",
    "            storage=LazyTensorStorage(self.replay_buffer_capacity),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "    @discount.validator\n",
    "    def check_discount(self, attribute, value):\n",
    "        if not 0 <= value <= 1:\n",
    "            raise ValueError(\"Discount factor must lie in [0,1]\")\n",
    "\n",
    "    @learning_rate.validator\n",
    "    def check_learning_rate(self, attribute, value):\n",
    "        if not 0 <= value < 1:\n",
    "            raise ValueError(\"Learning rate must lie in [0,1)\")\n",
    "\n",
    "    def update_state_history(self, state: Tuple[float]):\n",
    "        \"\"\"Update the history of states with the new state.\"\"\"\n",
    "        self.state_history.append(state)\n",
    "        if len(self.state_history) > self.sequence_length:\n",
    "            self.state_history.pop(0)\n",
    "        # Add zero padding if the state history is shorter than the sequence length\n",
    "        while len(self.state_history) < self.sequence_length:\n",
    "            self.state_history.insert(0, tuple(0.0 for _ in state))\n",
    "\n",
    "    def play_price(self, state: Tuple[float], action_space: List[float], n_period: int, t: int) -> float:\n",
    "        \"\"\"Returns an action by either following greedy policy or experimentation.\"\"\"\n",
    "        # Update state history\n",
    "        self.update_state_history(self.scale_sequence(state, action_space))\n",
    "\n",
    "        # Initialize LSTM network if necessary\n",
    "        if not self.lstm:\n",
    "            self.lstm = self.initialize_network(len(state), len(action_space))\n",
    "\n",
    "        # Play action\n",
    "        if self.decision.explore(n_period, t):\n",
    "            chosen_action = random.choice(action_space)\n",
    "            return chosen_action\n",
    "        else:\n",
    "            # Use state history as input to the LSTM network\n",
    "            states_input = torch.tensor(self.state_history).float().unsqueeze(0)\n",
    "            action_values = self.lstm(states_input).detach().numpy()\n",
    "            if sum(np.isclose(action_values[0], action_values[0].max())) > 1:\n",
    "                optimal_action_index = np.random.choice(\n",
    "                    np.flatnonzero(np.isclose(action_values[0], action_values[0].max()))\n",
    "                )\n",
    "            else:\n",
    "                optimal_action_index = np.argmax(action_values[0])\n",
    "            chosen_action = action_space[optimal_action_index]\n",
    "            return chosen_action\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List[float],\n",
    "        previous_state: Tuple[float],\n",
    "        state: Tuple[float],\n",
    "        next_state: Tuple[float],\n",
    "    ):\n",
    "        \"\"\"Update the LSTM network based on the observed rewards and actions.\"\"\"\n",
    "\n",
    "        # Add transition to replay buffer\n",
    "        scaled_next_state = self.scale_sequence([next_state], action_space)[0]\n",
    "        next_state_history = self.state_history[-(self.sequence_length - 1):] + [scaled_next_state]\n",
    "\n",
    "        action_index = torch.tensor([action_space.index(action)], dtype=torch.int64)\n",
    "        transition = TensorDict(\n",
    "            {\n",
    "            \"state\": torch.tensor(self.state_history[-self.sequence_length:], dtype=torch.float32),\n",
    "            \"action\": action_index,  # Use the correct dtype for the action index\n",
    "            \"reward\": torch.tensor([reward], dtype=torch.float32),  # Wrap scalar in a list\n",
    "            \"next_state\": torch.tensor(next_state_history, dtype=torch.float32),\n",
    "            \"done\": torch.tensor([0.0], dtype=torch.float32),  # Wrap scalar in a list\n",
    "            },\n",
    "            batch_size=[],  # No batch dimension here\n",
    "        )\n",
    "\n",
    "        self.replay_buffer.add(transition)\n",
    "\n",
    "        # Train only if enough samples are available\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        # Sample a batch of transitions\n",
    "        batch = self.replay_buffer.sample()\n",
    "            \n",
    "        states = batch[\"state\"]\n",
    "        actions = batch[\"action\"].squeeze(1).long()  # Ensure actions are of type int64\n",
    "        rewards = batch[\"reward\"].squeeze(1)\n",
    "        next_states = batch[\"next_state\"]\n",
    "        dones = batch[\"done\"].squeeze(1)\n",
    "\n",
    "        # Get the local estimates from the LSTM network\n",
    "        q_values = self.lstm(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Compute the target Q-values using the target network\n",
    "        next_q_values = self.target_lstm(next_states).max(1)[0].detach()\n",
    "        targets = rewards + self.discount * (1 - dones) * next_q_values\n",
    "\n",
    "        # Compute loss and update the network\n",
    "        optimizer = optim.Adam(self.lstm.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.MSELoss()(q_values, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the target network periodically\n",
    "        self.update_counter += 1\n",
    "        if self.update_counter % self.update_target_after == 0:\n",
    "            self.target_lstm.load_state_dict(self.lstm.state_dict())\n",
    "            if self.debug:\n",
    "                print(\"Target network updated.\")\n",
    "\n",
    "        # Store the loss value\n",
    "        self.loss_history.append(loss.item())\n",
    "\n",
    "    def initialize_network(self, n_agents: int, n_actions: int):\n",
    "        \"\"\"Create a neural network with one output node per possible action.\"\"\"\n",
    "        lstm = LSTMModel(input_size=n_agents, hidden_size=self.hidden_nodes, output_size=n_actions)\n",
    "        self.target_lstm = LSTMModel(input_size=n_agents, hidden_size=self.hidden_nodes, output_size=n_actions)\n",
    "        self.target_lstm.load_state_dict(lstm.state_dict())  # Synchronize weights initially\n",
    "        self.target_lstm.eval()  # Target network is not trained directly\n",
    "        return lstm\n",
    "    \n",
    "    def scale_sequence(self, sequences: List[Tuple], action_space: List) -> np.array:\n",
    "        \"\"\"Scale float input sequences to range from 0 to 1.\"\"\"\n",
    "        max_action = max(action_space)\n",
    "        min_action = min(action_space)\n",
    "        return np.array([\n",
    "            np.multiply(np.divide(np.array(seq) - min_action, max_action - min_action), 1) for seq in sequences\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pyTorch Replay Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 0/5000 (0.00%)\n",
      "Period 50/5000 (1.00%)\n",
      "Period 100/5000 (2.00%)\n"
     ]
    }
   ],
   "source": [
    "def test_lstm_replay_agent():\n",
    "\t# Create an environment with one LSTMReplayAgent and one AlwaysDefectAgent\n",
    "\tenv = DiscreteSynchronEnvironment(\n",
    "\t\tmarkup=0.1,\n",
    "\t\tn_periods=5000,\n",
    "\t\tpossible_prices=[],\n",
    "\t\tn_prices=15,\n",
    "\t\tdemand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "\t\thistory_after=0,\n",
    "\t\tagents=[\n",
    "\t\t\tLSTMReplayAgent(\n",
    "\t\t\t\tdiscount=0.95,\n",
    "\t\t\t\tlearning_rate=0.01,\n",
    "\t\t\t\tdecision=DecreasingEpsilonGreedy(),\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t\tsequence_length=5,\n",
    "\t\t\t\tbatch_size=32,\n",
    "\t\t\t\tupdate_target_after=100,\n",
    "\t\t\t\tdebug=False,\n",
    "\t\t\t\treplay_buffer_capacity=1000,\n",
    "\t\t\t),\n",
    "\t\t\tAlwaysMaxAgent(\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t),\n",
    "\t\t],\n",
    "\t\tdebug = False,\n",
    "\t)\n",
    "\n",
    "\t# Simulate the environment\n",
    "\tenv.play_game()\n",
    "\n",
    "\t# Analyze and visualize results\n",
    "\tprice_history_lstm = [price[0] for price in env.price_history]\n",
    "\tprice_history_defect = [price[1] for price in env.price_history]\n",
    "\n",
    "\t# Plot price history\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(price_history_lstm, label=\"LSTM Replay Agent\")\n",
    "\tplt.plot(price_history_defect, label=\"Test Agent\")\n",
    "\tplt.title(\"Price History: LSTM Replay Agent vs Test Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Price\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Plot reward history\n",
    "\treward_history_lstm = [reward[0] for reward in env.reward_history]\n",
    "\treward_history_defect = [reward[1] for reward in env.reward_history]\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(reward_history_lstm, label=\"LSTM Replay Agent\")\n",
    "\tplt.plot(reward_history_defect, label=\"Test Agent\")\n",
    "\tplt.title(\"Reward History: LSTM Replay Agent vs Test Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Reward\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Plot loss history\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(env.agents[0].loss_history, label=\"LSTM Replay Agent Loss\")\n",
    "\tplt.title(\"Loss History\")\n",
    "\tplt.xlabel(\"Training Steps\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Print action-values for the last state\n",
    "\tlast_state = env.price_history[-1]\n",
    "\tstates_input = torch.tensor(env.agents[0].scale_sequence([last_state], env.possible_prices)).float().unsqueeze(0)\n",
    "\taction_values = env.agents[0].lstm(states_input).detach().numpy()\n",
    "\tprint(\"Action-values for the last state:\", action_values)\n",
    "\n",
    "test_lstm_replay_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class LSTMTargetAgent(LSTMReplayAgent):\n",
    "    \"\"\"LSTM Agent with Target Network but without Replay Buffer\"\"\"\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List[float],\n",
    "        previous_state: Tuple[float],\n",
    "        state: Tuple[float],\n",
    "        next_state: Tuple[float],\n",
    "    ):\n",
    "        \"\"\"Train the LSTM network using the target network.\"\"\"\n",
    "        # Update state history\n",
    "        self.update_state_history(state)\n",
    "\n",
    "        # Create a sequence of state history length for the next state\n",
    "        next_state_history = self.state_history[-self.sequence_length:] + [next_state]\n",
    "        # Scale the input sequences\n",
    "        states_input = torch.tensor(self.scale_sequence(self.state_history, action_space)).float().unsqueeze(0)\n",
    "        next_states_input = torch.tensor(self.scale_sequence(next_state_history, action_space)).float().unsqueeze(0)\n",
    "\n",
    "        # Compute the target Q-values using the target network\n",
    "        with torch.no_grad():\n",
    "            next_optimal_q = self.target_lstm(next_states_input).max().item()\n",
    "            target = reward + self.discount * next_optimal_q\n",
    "\n",
    "        # Get the local estimates from the LSTM network\n",
    "        local_estimates = self.lstm(states_input)\n",
    "        action_idx = np.atleast_1d(action_space == action).nonzero()[0]\n",
    "        target_tensor = local_estimates.clone().detach()\n",
    "        target_tensor[0, action_idx] = target\n",
    "\n",
    "        # Update the LSTM network using backpropagation\n",
    "        optimizer = optim.Adam(self.lstm.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.MSELoss()(local_estimates, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the target network periodically\n",
    "        self.update_counter += 1\n",
    "        if self.update_counter >= self.update_target_after:\n",
    "            self.target_lstm.load_state_dict(self.lstm.state_dict())\n",
    "            self.update_counter = 0\n",
    "            #print(\"Target network updated.\")\n",
    "\n",
    "        # Store the loss value\n",
    "        self.loss_history.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm_target_vs_always_max():\n",
    "    # Create an environment with one LSTMTargetAgent and one AlwaysMaxAgent\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=50000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=100,\n",
    "        agents=[\n",
    "            LSTMTargetAgent(\n",
    "                discount=0.95,\n",
    "                learning_rate=0.001,\n",
    "                decision=DecreasingEpsilonGreedy(),\n",
    "                marginal_cost=1.0,\n",
    "                quality=2.0,\n",
    "                sequence_length=10,\n",
    "                update_target_after=250,\n",
    "                batch_size=8,\n",
    "            ),\n",
    "            AlwaysMaxAgent(\n",
    "                marginal_cost=1.0,\n",
    "                quality=2.0,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Simulate the environment\n",
    "    env.play_game()\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_lstm = [price[0] for price in env.price_history]\n",
    "    price_history_max = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_history_lstm, label=\"LSTM Target Agent\")\n",
    "    plt.plot(price_history_max, label=\"Always Min Agent\")\n",
    "    plt.title(\"Price History: LSTM Target Agent vs Always Max Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_lstm = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_max = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(reward_history_lstm, label=\"LSTM Target Agent\")\n",
    "    plt.plot(reward_history_max, label=\"Always Min Agent\")\n",
    "    plt.title(\"Reward History: LSTM Target Agent vs Always Min Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_lstm_target_vs_always_max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN implementation (adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyTensorStorage\n",
    "from tensordict import TensorDict\n",
    "from typing import List, Tuple\n",
    "import attr\n",
    "import numpy as np\n",
    "\n",
    "class DQNModel(nn.Module):\n",
    "    \"\"\"Simple feedforward neural network for DQN.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DQNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class DQNAgent(AgentStrategy):\n",
    "    \"\"\"DQN Agent with PyTorch and TensorDictReplayBuffer.\"\"\"\n",
    "\n",
    "    # Neural Network\n",
    "    qnetwork: DQNModel = attr.ib(default=None)\n",
    "    target_qnetwork: DQNModel = attr.ib(default=None, init=False)\n",
    "    hidden_nodes: int = attr.ib(default=32)\n",
    "\n",
    "    # Replay Buffer\n",
    "    replay_buffer_capacity: int = attr.ib(default=1000)\n",
    "    batch_size: int = attr.ib(default=32)\n",
    "\n",
    "    # General\n",
    "    decision: ExplorationStrategy = attr.ib(factory=EpsilonGreedy)\n",
    "    discount: float = attr.ib(default=0.95)\n",
    "    learning_rate: float = attr.ib(default=0.01)\n",
    "    update_target_after: int = attr.ib(default=100)\n",
    "    update_counter: int = attr.ib(default=0, init=False)\n",
    "    loss_history: List[float] = attr.ib(factory=list, init=False)\n",
    "\n",
    "    # Debugging\n",
    "    debug: bool = attr.ib(default=False)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        # Initialize replay buffer\n",
    "        self.replay_buffer = TensorDictReplayBuffer(\n",
    "            storage=LazyTensorStorage(self.replay_buffer_capacity),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "    @discount.validator\n",
    "    def check_discount(self, attribute, value):\n",
    "        if not 0 <= value <= 1:\n",
    "            raise ValueError(\"Discount factor must lie in [0,1]\")\n",
    "\n",
    "    @learning_rate.validator\n",
    "    def check_learning_rate(self, attribute, value):\n",
    "        if not 0 <= value < 1:\n",
    "            raise ValueError(\"Learning rate must lie in [0,1)\")\n",
    "\n",
    "    def play_price(self, state: Tuple[float], action_space: List[float], n_period: int, t: int) -> float:\n",
    "        \"\"\"Select an action using epsilon-greedy policy.\"\"\"\n",
    "        if self.debug:\n",
    "            print(f\"\\n\")\n",
    "\n",
    "        # Initialize Q-network if necessary\n",
    "        if not self.qnetwork:\n",
    "            self.qnetwork = self.initialize_network(len(state), len(action_space))\n",
    "            if self.debug:\n",
    "                print(f\"Initialized Q-network with input size {len(state)} and output size {len(action_space)}\")\n",
    "\n",
    "        # Exploration or exploitation\n",
    "        if self.decision.explore(n_period, t):\n",
    "            chosen_action = random.choice(action_space)\n",
    "            if self.debug:\n",
    "                print(f\"Exploration chosen. Random action: {chosen_action}\")\n",
    "            return chosen_action\n",
    "        else:\n",
    "            state = self.scale(state, action_space)\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "            action_values = self.qnetwork(state_tensor).detach().numpy()\n",
    "            if self.debug:\n",
    "                print(f\"Action values: {action_values}\")\n",
    "            \n",
    "            # Handle ties by checking if multiple actions have the same maximum value\n",
    "            if sum(np.isclose(action_values[0], action_values[0].max())) > 1:\n",
    "                optimal_action_index = np.random.choice(\n",
    "                    np.flatnonzero(np.isclose(action_values[0], action_values[0].max()))\n",
    "                )\n",
    "            else:\n",
    "                optimal_action_index = np.argmax(action_values[0])\n",
    "\n",
    "            chosen_action = action_space[optimal_action_index]\n",
    "            if self.debug:\n",
    "                print(f\"Chosen action: {chosen_action}\")\n",
    "            return chosen_action\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List[float],\n",
    "        previous_state: Tuple[float],\n",
    "        state: Tuple[float],\n",
    "        next_state: Tuple[float],\n",
    "    ):\n",
    "        \"\"\"Train the Q-network using transitions from the replay buffer.\"\"\"\n",
    "        if self.debug:\n",
    "            print(f\"State: {state}, next_state: {next_state}, action: {action}, reward: {reward}\")\n",
    "        # Action index\n",
    "        action_index = action_space.index(action)# Scale the state\n",
    "        state = self.scale(state, action_space)\n",
    "        next_state = self.scale(next_state, action_space)\n",
    "        # Add transition to replay buffer\n",
    "        transition = TensorDict(\n",
    "            {\n",
    "            \"state\": torch.tensor(state, dtype=torch.float32),\n",
    "            \"action_index\": torch.tensor([action_index], dtype=torch.long),\n",
    "            \"reward\": torch.tensor([reward], dtype=torch.float32),\n",
    "            \"next_state\": torch.tensor(next_state, dtype=torch.float32),\n",
    "            \"done\": torch.tensor([0.0], dtype=torch.float32),  # Assuming no terminal state\n",
    "            },\n",
    "            batch_size=[],  # No batch dimension here\n",
    "        )\n",
    "        self.replay_buffer.add(transition)\n",
    "\n",
    "        # Train only if enough samples are available\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            if self.debug:\n",
    "                print(f\"Not enough samples in replay buffer. Current size: {len(self.replay_buffer)}\")\n",
    "            return\n",
    "\n",
    "        # Sample a batch of transitions\n",
    "        batch = self.replay_buffer.sample()\n",
    "        states = batch[\"state\"]\n",
    "        action_indices = batch[\"action_index\"].squeeze(1)\n",
    "        rewards = batch[\"reward\"].squeeze(1)\n",
    "        next_states = batch[\"next_state\"]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"From RB; States: {states}, next_states: {next_states}, action_indices: {action_indices}, reward: {rewards}\")\n",
    "        \n",
    "        # Compute max predicted Q-values for next state using the target network\n",
    "        next_q_values = self.target_qnetwork(next_states).max(1)[0].detach()\n",
    "       \n",
    "        # Compute Q targets for current states\n",
    "        targets = rewards + self.discount * next_q_values\n",
    "\n",
    "        # Get current Q values from local model and update them\n",
    "        q_values = self.qnetwork(states).gather(1, action_indices.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"next_q_values: {next_q_values}\")\n",
    "            print(f\"Targets: {targets}\")    \n",
    "            print(f\"Q-values: {q_values}\")\n",
    "\n",
    "        # Compute loss and update the network\n",
    "        optimizer = optim.Adam(self.qnetwork.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.MSELoss()(q_values, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the target network periodically\n",
    "        self.update_counter += 1\n",
    "        if self.update_counter % self.update_target_after == 0:\n",
    "            self.target_qnetwork.load_state_dict(self.qnetwork.state_dict())\n",
    "            if self.debug:\n",
    "                print(\"Target network updated.\")\n",
    "\n",
    "        # Store the loss value\n",
    "        self.loss_history.append(loss.item())\n",
    "        if self.debug:\n",
    "            print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    def initialize_network(self, input_size: int, output_size: int) -> DQNModel:\n",
    "        \"\"\"Initialize the Q-network and target network.\"\"\"\n",
    "        qnetwork = DQNModel(input_size=input_size, hidden_size=self.hidden_nodes, output_size=output_size)\n",
    "        self.target_qnetwork = DQNModel(input_size=input_size, hidden_size=self.hidden_nodes, output_size=output_size)\n",
    "        self.target_qnetwork.load_state_dict(qnetwork.state_dict())  # Synchronize weights initially\n",
    "        self.target_qnetwork.eval()  # Target network is not trained directly\n",
    "        return qnetwork\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale(inputs: Tuple, action_space: List) -> np.array:\n",
    "        \"\"\"Scale float input to range from 0 to 1.\"\"\"\n",
    "        max_action = max(action_space)\n",
    "        min_action = min(action_space)\n",
    "        return np.multiply(np.divide(np.array(inputs) - min_action, max_action - min_action), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_dqn_agent():\n",
    "    # Create an environment with one DQNAgent and one AlwaysDefectAgent\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=10000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=100,\n",
    "        agents=[\n",
    "            DQNAgent(\n",
    "                discount=0.95,\n",
    "                learning_rate=0.001,\n",
    "                decision=DecreasingEpsilonGreedy(),\n",
    "                marginal_cost=1.0,\n",
    "                quality=2.0,\n",
    "                batch_size=32,\n",
    "                update_target_after=50,\n",
    "                hidden_nodes=32,\n",
    "                debug=False,\n",
    "            ),\n",
    "            AlwaysMaxAgent(\n",
    "                marginal_cost=1.0,\n",
    "                quality=2.0,\n",
    "            ),\n",
    "        ],\n",
    "        debug=False,\n",
    "    )\n",
    "\n",
    "    # Simulate the environment\n",
    "    env.play_game()\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_dqn = [price[0] for price in env.price_history]\n",
    "    price_history_defect = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot loss history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(env.agents[0].loss_history, label=\"DQN Agent Loss\")\n",
    "    plt.title(\"Loss History\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_history_dqn, label=\"DQN Agent\")\n",
    "    #plt.plot(price_history_defect, label=\"Test Agent\")\n",
    "    plt.title(\"Price History: DQN Agent vs Test Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_dqn = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_defect = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(reward_history_dqn, label=\"DQN Agent\")\n",
    "    #plt.plot(reward_history_defect, label=\"Test Agent\")\n",
    "    plt.title(\"Reward History: DQN Agent vs Test Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Overlay rewards and prices for comparison\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot rewards on the left y-axis\n",
    "    ax1.set_xlabel(\"Time Step\")\n",
    "    ax1.set_ylabel(\"Reward\", color=\"blue\")\n",
    "    ax1.plot(reward_history_dqn[-30:], label=\"Reward\", color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # Plot prices on the right y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Price\", color=\"orange\")\n",
    "    ax2.plot(price_history_dqn[-30:], label=\"Price\", color=\"orange\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"orange\")\n",
    "\n",
    "    plt.title(\"Reward and Price History: DQN Agent\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # Plot rewards against prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(price_history_dqn, reward_history_dqn, alpha=0.5, label=\"DQN Agent\")\n",
    "    plt.title(\"Rewards vs Prices: DQN Agent\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_dqn_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN tensorFlow\n",
    "original by Hettich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import attr\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from price_simulator.src.algorithm.agents.buffer import ReplayBuffer\n",
    "from price_simulator.src.algorithm.agents.simple import AgentStrategy\n",
    "from price_simulator.src.algorithm.policies import EpsilonGreedy, ExplorationStrategy\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class DQN(AgentStrategy):\n",
    "    \"\"\"Deep-Q-Netowrks Agent with discounted reward formulation\"\"\"\n",
    "\n",
    "    # Q-Network\n",
    "    qnetwork_target: keras.models = attr.ib(default=None)\n",
    "    qnetwork_local: keras.models = attr.ib(default=None)\n",
    "    update_target_after: int = attr.ib(default=100)\n",
    "    replay_memory: ReplayBuffer = attr.ib(factory=ReplayBuffer)\n",
    "    batch_size: int = attr.ib(default=32)\n",
    "    update_counter: int = attr.ib(default=0)\n",
    "    hidden_nodes: int = attr.ib(default=32)\n",
    "\n",
    "    # General\n",
    "    decision: ExplorationStrategy = attr.ib(factory=EpsilonGreedy)\n",
    "    discount: float = attr.ib(default=0.95)\n",
    "    learning_rate: float = attr.ib(default=0.1)\n",
    "\n",
    "    @discount.validator\n",
    "    def check_discount(self, attribute, value):\n",
    "        if not 0 <= value <= 1:\n",
    "            raise ValueError(\"Discount factor must lie in [0,1]\")\n",
    "\n",
    "    @learning_rate.validator\n",
    "    def check_learning_rate(self, attribute, value):\n",
    "        \"\"\"For learning_rate = 0, the algorithm does not learn at all.\n",
    "        For learning_rate = 1, it immediately forgets what it has learned in the past.\n",
    "        \"\"\"\n",
    "        if not 0 <= value < 1:\n",
    "            raise ValueError(\"Learning rate must lie in [0,1)\")\n",
    "\n",
    "    def who_am_i(self) -> str:\n",
    "        # TODO better who am i\n",
    "        return type(self).__name__ + \" (gamma: {}, alpha: {}, policy: {}, quality: {}, mc: {})\".format(\n",
    "            self.discount, self.learning_rate, self.decision.who_am_i(), self.quality, self.marginal_cost\n",
    "        )\n",
    "\n",
    "    def play_price(self, state: Tuple[float], action_space: List[float], n_period: int, t: int) -> float:\n",
    "        \"\"\"Returns an action by either following greedy policy or experimentation.\"\"\"\n",
    "\n",
    "        # init q networks if necessary\n",
    "        if not self.qnetwork_target or not self.qnetwork_local:\n",
    "            self.qnetwork_target = self.initialize_network(len(state), len(action_space))\n",
    "            self.qnetwork_local = self.initialize_network(len(state), len(action_space))\n",
    "            self.qnetwork_target.set_weights(self.qnetwork_local.get_weights())\n",
    "\n",
    "        # play action\n",
    "        if self.decision.explore(n_period, t):\n",
    "            return random.choice(action_space)\n",
    "        else:\n",
    "            action_values = self.qnetwork_local.predict(np.expand_dims(self.scale(state, action_space), axis=0))\n",
    "            if sum(np.isclose(action_values[0], action_values[0].max())) > 1:\n",
    "                optimal_action_index = np.random.choice(\n",
    "                    np.flatnonzero(np.isclose(action_values[0], action_values[0].max()))\n",
    "                )\n",
    "            else:\n",
    "                optimal_action_index = np.argmax(action_values[0])\n",
    "            return action_space[optimal_action_index]\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        previous_reward: float,\n",
    "        reward: float,\n",
    "        previous_action: float,\n",
    "        action: float,\n",
    "        action_space: List,\n",
    "        previous_state: Tuple,\n",
    "        state: Tuple,\n",
    "        next_state: Tuple,\n",
    "    ):\n",
    "        # store experience in buffer (action is converted to index)\n",
    "        action = np.where(action_space == action)[0]\n",
    "        state = self.scale(state, action_space)\n",
    "        next_state = self.scale(next_state, action_space)\n",
    "        self.replay_memory.add(state, action, reward, next_state)\n",
    "\n",
    "        if len(self.replay_memory) > self.batch_size:\n",
    "\n",
    "            # get training sample\n",
    "            states, actions, rewards, next_states = self.replay_memory.sample(self.batch_size)\n",
    "\n",
    "            # Get max predicted Q values (for next states) from target model\n",
    "            next_optimal_q = np.amax(self.qnetwork_target.predict(next_states), axis=1, keepdims=True)\n",
    "\n",
    "            # Compute Q targets for current states\n",
    "            targets = rewards + self.discount * next_optimal_q\n",
    "\n",
    "            # Get current Q values from local model and update them\n",
    "            # with better estimates (target) for the played actions\n",
    "            local_estimates = self.qnetwork_local.predict(states)\n",
    "            local_estimates[np.arange(len(actions)), actions.flatten()] = targets.flatten()\n",
    "\n",
    "            # perform gradient descent step on local network\n",
    "            self.qnetwork_local.fit(states, local_estimates, epochs=1, verbose=0, batch_size=self.batch_size)\n",
    "\n",
    "            # update target_qnetwork after some periods\n",
    "            self.update_counter += 1\n",
    "            if self.update_counter == self.update_target_after:\n",
    "                self.qnetwork_target.set_weights(self.qnetwork_local.get_weights())\n",
    "                self.update_counter = 0\n",
    "                print(\"I updated my target model\")\n",
    "\n",
    "    def initialize_network(self, n_agents: int, n_actions: int):\n",
    "        \"\"\"Create a neuronal network with one output node per possible action\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(int(self.hidden_nodes), input_dim=n_agents, activation=\"relu\"))\n",
    "        model.add(Dense(int(self.hidden_nodes), activation=\"relu\"))\n",
    "        model.add(Dense(n_actions, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def scale(inputs: Tuple, action_space: List) -> np.array:\n",
    "        \"\"\"Scale float input to range from 0 to 1.\"\"\"\n",
    "        max_action = max(action_space)\n",
    "        min_action = min(action_space)\n",
    "        return np.multiply(np.divide(np.array(inputs) - min_action, max_action - min_action), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn_vs_always_max():\n",
    "\t# Create an environment with one DQN agent and one AlwaysMaxAgent\n",
    "\tenv = DiscreteSynchronEnvironment(\n",
    "\t\tmarkup=0.1,\n",
    "\t\tn_periods=100,\n",
    "\t\tpossible_prices=[],\n",
    "\t\tn_prices=15,\n",
    "\t\tdemand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "\t\thistory_after=0,\n",
    "\t\tagents=[\n",
    "\t\t\tDQN(\n",
    "\t\t\t\tdiscount=0.95,\n",
    "\t\t\t\tlearning_rate=0.001,\n",
    "\t\t\t\tdecision=DecreasingEpsilonGreedy(),\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t),\n",
    "\t\t\tAlwaysMaxAgent(\n",
    "\t\t\t\tmarginal_cost=1.0,\n",
    "\t\t\t\tquality=2.0,\n",
    "\t\t\t),\n",
    "\t\t],\n",
    "\t\tdebug=False,\n",
    "\t)\n",
    "\n",
    "\t# Simulate the environment\n",
    "\tenv.play_game()\n",
    "\n",
    "\t# Analyze and visualize results\n",
    "\tprice_history_dqn = [price[0] for price in env.price_history]\n",
    "\tprice_history_max = [price[1] for price in env.price_history]\n",
    "\n",
    "\t# Plot price history\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(price_history_dqn, label=\"DQN Agent\")\n",
    "\tplt.plot(price_history_max, label=\"Always Max Agent\")\n",
    "\tplt.title(\"Price History: DQN Agent vs Always Max Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Price\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Plot reward history\n",
    "\treward_history_dqn = [reward[0] for reward in env.reward_history]\n",
    "\treward_history_max = [reward[1] for reward in env.reward_history]\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.plot(reward_history_dqn, label=\"DQN Agent\")\n",
    "\tplt.plot(reward_history_max, label=\"Always Max Agent\")\n",
    "\tplt.title(\"Reward History: DQN Agent vs Always Max Agent\")\n",
    "\tplt.xlabel(\"Time\")\n",
    "\tplt.ylabel(\"Reward\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t# Plot rewards against prices for the DQN agent\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tplt.scatter(price_history_dqn, reward_history_dqn, alpha=0.5, label=\"DQN Agent\")\n",
    "\tplt.title(\"Rewards vs Prices: DQN Agent\")\n",
    "\tplt.xlabel(\"Price\")\n",
    "\tplt.ylabel(\"Reward\")\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "test_dqn_vs_always_max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with original import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import price_simulator.src.utils.analyzer as Analyzer\n",
    "from price_simulator.src.algorithm.agents.approximate import DiffDQN\n",
    "from price_simulator.src.algorithm.agents.simple import AlwaysDefectAgent\n",
    "from price_simulator.src.algorithm.agents.tabular import Qlearning\n",
    "#from price_simulator.src.algorithm.demand import LogitDemand\n",
    "#from price_simulator.src.algorithm.environment import DiscreteSynchronEnvironment\n",
    "#from price_simulator.src.algorithm.policies import DecreasingEpsilonGreedy\n",
    "\n",
    "\n",
    "def run():\n",
    "    env = DiscreteSynchronEnvironment(\n",
    "        markup=0.1,\n",
    "        n_periods=40000,\n",
    "        possible_prices=[],\n",
    "        n_prices=15,\n",
    "        demand=LogitDemand(outside_quality=0.0, price_sensitivity=0.25),\n",
    "        history_after=0,\n",
    "        agents=[\n",
    "            Qlearning(\n",
    "                discount=0.95, learning_rate=0.125, decision=DecreasingEpsilonGreedy(), marginal_cost=1.0, quality=2.0,\n",
    "            ),\n",
    "            AlwaysMaxAgent(\n",
    "                marginal_cost=1.0, quality=2.0,\n",
    "            ),            \n",
    "        ],\n",
    "    )\n",
    "    env.play_game()\n",
    "    Analyzer.analyze(env)\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    price_history_qlearning = [price[0] for price in env.price_history]\n",
    "    price_history_max = [price[1] for price in env.price_history]\n",
    "\n",
    "    # Plot price history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_history_qlearning, label=\"Q-Learning Agent\")\n",
    "    #plt.plot(price_history_max, label=\"Always Max Agent\")\n",
    "    plt.title(\"Price History: Q-Learning Agent vs Always Max Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot reward history\n",
    "    reward_history_qlearning = [reward[0] for reward in env.reward_history]\n",
    "    reward_history_max = [reward[1] for reward in env.reward_history]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(reward_history_qlearning, label=\"Q-Learning Agent\")\n",
    "    #plt.plot(reward_history_max, label=\"Always Max Agent\")\n",
    "    plt.title(\"Reward History: Q-Learning Agent vs Always Max Agent\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot rewards against prices for the Q-Learning agent\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(price_history_qlearning, reward_history_qlearning, alpha=0.5, label=\"Q-Learning Agent\")\n",
    "    plt.title(\"Rewards vs Prices: Q-Learning Agent\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
